# Analysis of binary and ordinal outcomes {#binOut}

Binary outcomes are ubiquitous in medical research and the comparison
of binary outcomes in RCTs is very common.  This chapter discusses
various statistical quantities that can be calculated for comparing
binary outcomes. We discuss statistical tests, suitable effect measures and
methods to adjust for possible baseline variables. Ordinal outcomes 
are also discussed at the end of this chapter. 

## Comparison of two proportions

Throughout this section, we will work with the following example.

:::{.example #apsac}
The APSAC study is an RCT comparing a new thrombolytikum (APSAC) with the 
standard treatment (Heparin) in patients with acute cardiac infarction [@meinertz].
The outcome is mortality within 28 days of hospital stay. Table \@ref(tab:apsac) 
summarizes the results of this study, including 95\% Wilson CIs for the 
proportion of patients who died in the respective treatment groups.
:::


```{r echo=F}
library(biostatUZH)
w1 <- wilson(x=9,n=162)*100
w2 <- wilson(x=19,n=151)*100
``` 


```{r apsac, echo = FALSE}
library(dplyr)
library(kableExtra)
# Sample data for the table
data <- data.frame(
  Therapy = c("APSAC", "Heparin", "Total"),
  dead = c(9, 19, 28),
  alive = c(153, 132, 285),
  total = c(162, 151, 313),
  Percent_dead = c("5.6%", "12.6%", ""),
  Standard_error = c("1.8%", "2.7%", ""),
  Wilson_CI = c(paste0(format(w1[1], digits=1, nsmall=1), " to ", format(w1[3], digits=1, nsmall=1)), 
                paste0(format(w2[1], digits=1, nsmall=1), " to ", format(w2[3], digits=1, nsmall=1)), 
                "")
)

kable(data, caption = "Results of the APSAC study.", 
      col.names = c("Therapy", "Dead", "Alive", "Total", "Percent Dead", 
                    "Standard Error", "95% Wilson-CI"), label = NA) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = F, position = "center")
```


A visual comparison for the two separate CIs in Figure \@ref(fig:apsacfig) 
shows that they overlap. However, overlapping CIs are not necessarily an
indication for a non-significant treatment effect. Instead, we should rather 
look at CIs for combined effect measures such as the ones presented in Definition \@ref(def:twoprops).


```{r apsacfig, fig.cap = "95\\% Wilson confidence intervals for the death risks in the APSAC study.", echo=F, warning=FALSE, fig.height=2}
par(las=1)
alpha <- 0.05
za <- qnorm(1 - alpha / 2)
d1 <- 9
n1 <- 162
p1 <- d1/n1
se.p1 <- sqrt(p1*(1-p1)/n1)

d2 <- 19
n2 <- 151
p2 <- d2/n2
se.p2 <- sqrt(p2*(1-p2)/n2)

## ci.p1 <- c(p1-1.96*se.p1,p1+1.96*se.p1)
## ci.p2 <- c(p2-1.96*se.p2,p2+1.96*se.p2)
ci.p1 <- wilson(x=9,n=162)[c(1,3)]
ci.p2 <- wilson(x=19,n=151)[c(1,3)]

arr <- p1-p2
p <- (d1+d2)/(n1+n2)
se.arr <- sqrt(se.p1^2+se.p2^2)
ci.arr <- c(arr-1.96*se.arr,arr+1.96*se.arr)

rr <- p1 / p2
rrr <- 1-rr
se.log.rr <- sqrt(1 / d1 - 1 / n1 + 1 / d2 - 1 / n2)


or <- d1 / (n1 - d1) / (d2 / (n2 - d2))
se.log.or <- sqrt(1 / d1 + 1 / (n1 - d1) + 1 / d2 + 1 / (n2 - d2))

nnt <- 1 / abs(p1 - p2)
ci.nnt <- 1 / abs(ci.arr)
par(mar = c(4, 4, 2, 0), cex=1)
plot(c(0,0), type = "n", xlim=c(0, 18), ylim = c(0.9, 1.8), ylab="", 
xlab="Death risk (in %)", axes=F)
axis(1, at=c(0,5,10,15,20, 25), labels=c(0,5,10,15,20, 25))
axis(2, at=c(1.7, 1.3), labels=c("APSAC", "Heparin"))
lines(ci.p1*100, rep(1.7, 2), col=3, lwd=2)
lines(ci.p2*100, rep(1.3, 2), col=2, lwd=2)
lines(rep(ci.p2[1]*100, 2), c(0.9, 2.1), col=1, lty=2)
lines(rep(ci.p1[2]*100, 2), c(0.9, 2.1), col=1, lty=2)
points(p1*100, 1.7, col=3, pch=19)
points(p2*100, 1.3, col=2, pch=19)
```


### Statistical tests

Commonly used tests to compare two proportions are the *$\chi^2$-test*
and *Fisher's "exact" test* for small samples.
The null hypothesis in these tests is that there is no difference 
between groups. 
Both methods give a $P$-value, but no effect measure. There is a second 
version of the $\chi^2$-test which uses a *continuity correction*. Furthermore,
there are at least *three* different versions to calculate the *two-sided* $P$-value 
for Fisher's "exact" test (see the `R` package `exact2x2` 
for details).

:::{.example #apsac name="continued"}
The $\chi^2$-test and Fisher's exact test are applied to the APSAC study in the 
 following `R` code:
:::

```{r echo=F}
APSAC.table <- matrix(c(9,153,19,132), ncol=2, byrow=T, 
                      dimnames = list(c("APSAC", "Heparin"),
                                    c("dead", "alive")))
```

```{r echo=TRUE}
## observed number of cases
print(APSAC.table)
## expected number of cases
print(chisq.test(APSAC.table)$expected)

# chi-squared test
chisq.test(APSAC.table, correct=FALSE)

# Fisher's test
fisher.test(APSAC.table)
```




Note that the function `fisher.test()` also provides an estimate
(`conditional MLE`) of the odds ratio (with 95% CI).
The output from the $\chi^2$-test can also be used to compute
an estimate of the relative risk based on the observed to expected death ratios. 
An approximate standard error of the log relative risk can be computed from the expected counts, so
a confidence interval for the relative risk can be calculated: 

```{r echo=TRUE}
mytest <- chisq.test(APSAC.table)
o <- mytest$observed[,"dead"]
e <- mytest$expected[,"dead"]
print(ratio <- (o/e))
## relative risk
print(RR <- ratio[1]/ratio[2])
## standard error of log relative risk
print(SElogRR <- sqrt(sum(1/e)))
``` 


```{r echo=FALSE, eval=TRUE}
printWaldCI(log(RR), SElogRR, FUN = exp)
``` 

The formula for the standard error given below in Section \@ref(sec:effectMeasures) is slightly more accurate and usually the preferred one. 


### Effect measures and confidence intervals{#sec:effectMeasures}

Let $\pi_0$ and $\pi_1$ denote the true risks of death in the control and intervention
group, respectively, with $\pi_0 \geq \pi_1$.

:::{.definition #twoprops}
The following quantities are used to compare $\pi_0$ and $\pi_1$: 

- The *absolute risk reduction*
$$\ARR  = \pi_0-\pi_1.$$
- The *number needed to treat*
$$\NNT = 1 / \ARR.$$

- The *relative risk*
$$\RR = {\pi_1}/{\pi_0}.$$

- The *relative risk reduction*
$$\RRR = \frac{\ARR}{\pi_0} = 1 - \RR.$$

- The *odds ratio*
$$\OR = \frac{\pi_1/(1-\pi_1)}{\pi_0/(1-\pi_0)}.$$
:::


No difference between groups (i.e. $\pi_0 = \pi_1$) corresponds to 
$\ARR=\RRR=0$ and $\RR=\OR=1$.
We now discuss each of these effect measures together with their CIs
using Example \@ref(exm:apsac).

#### Absolute Risk Reduction {-}

The ARR is also called *risk difference* ($\RD$) or *probability difference*. 
The estimated ARR

$$\widehat{\ARR} \ = \ 12.6\%-5.6\%=7\%$$

with standard error

\begin{equation}
(\#eq:arr.se)
\SE(\widehat{\ARR}) = \sqrt{\frac{\hat \pi_0 (1-\hat \pi_0)}{n_0}+\frac{\hat \pi_1 (1-\hat \pi_1)}{n_1}}= 3.2\%.
\end{equation}
   
$\widehat{\ARR}$ and $\SE(\widehat{\ARR})$ can be used to 
calculate a Wald CI for the ARR.
An improved Wilson CI for the ARR can be calculated using the 
*"square-and-add"* approach [@newcombe1998; @Newcombe], 
see Appendix \@ref(appCI:difference) and the function 
`biostatUZH::confIntSquareAdd()` for details.

```{r echo=F}
x1 <- 9
x2 <- 19
n1 <- 162
n2 <- 151
p1 <- x1/n1
p2 <- x2/n2
arr <- p1-p2
arr.se <- sqrt(p1*(1-p1)/n1+p2*(1-p2)/n2)
arr.lower <- arr - 1.96*arr.se
arr.upper <- arr + 1.96*arr.se

nnt.upper <- 1/arr.upper
nnt.lower <- 1/arr.lower
nnt <- 1/abs(arr)
``` 


The following R code provides both Wald and Wilson CIs for
the ARR in the APSAC study. They are visually compared in
Figure \@ref(fig:APSACartCIs).  There are no large differences
between the two types of confidence intervals, only the upper limit
of the Wilson is slightly larger than the corresponding Wald upper
limit.


```{r echo=TRUE}
library(biostatUZH)
x <- c(19, 9)
n <- c(151, 162)
print(confIntRiskDiff(x, n))
``` 

```{r echo=F}
res <- confIntRiskDiff(x, n)$CIs
arr.lower.w <- res[2,2]
arr.upper.w <- res[2,3]

nnt.lower.w <- 1/arr.lower.w 
nnt.upper.w <- 1/arr.upper.w 
``` 


Using articifial data, 
the lower plot in Figure \@ref(fig:APSACartCIs) highlights the distinct advantage 
of the Wilson confidence interval: its ability to prevent *overshoot*. 
Indeed, the upper limit of the Wald confidence
interval for the risk difference is larger than 1 whereas this is not
the case for the Wilson interval.


```{r echo=TRUE}
x.art <- c(11,1)
n.art <- c(12,12)
print(confIntRiskDiff(x.art, n.art))
```


```{r echo=F, warning=FALSE, fig.height=2.5}
library(gplots)

ci.rd <- confIntRiskDiff(x, n)

myx <- rep(ci.rd$rd,2)
li <- ci.rd$CIs[,2]*100
ui <- ci.rd$CIs[,3]*100

par(mar = c(4, 4, 4, 1), las = 1)
#plotCI(x=x, ui=ui, li=li, col="black", barcol="blue", lwd=1, err='y', axes=F, ylab="RD", xlab="Method", ylim=c(-0.2, 0.05))
plotCI(x=myx*100, y=c(1,2), ui=ui, li=li, col="black", barcol="blue", lwd=1, err='x', axes=F, xlab="Absolute Risk Reduction (in %)", ylab="", xlim=c(-0.05, 0.2)*100, ylim=c(0.5,2.5), pch=19)
axis(2, at=c(1,2), label=c("Wald", "Wilson"))
axis(1)
lines(rep(0,2), c(0,3), lty=2)
```



```{r APSACartCIs, fig.cap= "Wald and Wilson CIs for the ARR in the APSAC study (upper plot) and in an example with artifical data illustrating overshoot (lower plot).", echo=F, warning=FALSE, fig.height=2.5}
library(gplots)

ci.rd.art <- confIntRiskDiff(x.art, n.art)

myx <- rep(ci.rd.art$rd,2)
li <- ci.rd.art$CIs[,2]
ui <- ci.rd.art$CIs[,3]

par(mar = c(4, 4, 4, 1), las = 1)
#plotCI(x=x, ui=ui, li=li, col="black", barcol="blue", lwd=1, err='y', axes=F, ylab="RD", xlab="Method", ylim=c(-0.2, 0.05))
plotCI(x=myx*100, y=c(1,2), ui=ui*100, li=li*100, col="black", barcol="blue", lwd=1, err='x', axes=F, xlab="Absolute Risk Reduction (in %)", ylab="", ylim=c(0.5,2.5), xlim=c(0.4,1.2)*100, pch=19)
axis(2, at=c(1,2), label=c("Wald", "Wilson"))
axis(1)
lines(rep(100,2), c(0,3), lty=2, col=2)
text(115, 1, "Overshoot!", col="red")
```

#### Number Needed to Treat {-}


Suppose we have $n$ patients in each treatment group. 
The expected number of deaths in the control and intervention group are:
\begin{eqnarray*}
N_0 & = & n \, \pi_0, \\
N_1 & = & n \, \pi_1.
\end{eqnarray*}
The expected difference is therefore $N_0-N_1 = n \, (\pi_0-\pi_1)$.
Suppose we want the difference $N_0 - N_1$ to be one patient. 
The required sample size $n$ to achieve this is
\[
n = 1/(\pi_0-\pi_1) = 1/\ARR.
\]
This is the *number needed to treat*, the required number of patients to be treated with the intervention rather than control to avoid one death. Depending on the direction of the effect, the NNT is also called *number needed to benefit* or *number needed to harm*.

The interpretation of the estimated $\NNT$

$$\quad \widehat{\NNT} \ = \ 1/\widehat{\ARR} \ = 
\ 1 / `r round(abs(arr), 2)` \ = \ `r round(nnt, 1)`$$

in the APSAC study is the following: 
To avoid one death, we need to treat
$\widehat{\NNT} = `r round(abs(nnt),1)`$ patients with APSAC rather than
with Heparin. A confidence interval for $\NNT$ can be obtained by inverting the limits 
$\mbox{L}_{\mbox{ARR}}$ and $\mbox{U}_{\mbox{ARR}}$ 
of the CI for $\ARR$: 

```{r echo=TRUE}
(ci.arr <- confIntRiskDiff(x, n)$CIs[2,])
ci.ntt <- 1/ci.arr[c(3,2)]
colnames(ci.ntt) <- c("lower", "upper")
print(round(ci.ntt, 1))
``` 

The CI for $\NNT$ in the APSAC study is: $1 / `r round(abs(arr.upper.w),3)`$ to $1 / `r round(abs(arr.lower.w),3)`$ \ = \ $`r round(abs(nnt.upper.w),1)`$  to $`r round(abs(nnt.lower.w),1)`$.

Note that the CI for $\NNT$ is not well-defined if the CI for 
$\ARR$ contains 0. In that case, the confidence interval is actually
a confidence region, comprising two different intervals depending on the 
direction of the treatment effect [@altman1998].
This problem can be circumvented by plotting the number needed to treat on
the absolute risk reduction scale, as illustrated in the following example. 

:::{.example}

Figure \@ref(fig:NNTforest) shows a forest plot reproduced from @altman1998
where an overall number needed to benefit is calculated from a 
meta-analysis of data from 
randomized trials comparing bypass surgery with coronary angioplasty in 
relation to angina in one year [@Pocock1995].
For three studies (CABRI, RITA, EAST), the 95% confidence interval for NNT is a
regular interval and includes only values that indicate a benefit of therapy. 
However, for two other entries (GABI and Other) the confidence region for NNT 
splits into two intervals. For example, for GABI the two intervals are 7.5 to 
infinity for benefit and 14.5 to infinity for harm. This indicates that this 
trial is inconclusive regarding the direction of the treatment effect with
large uncertainty regarding the actual value of NNT. 
:::

```{r NNTforest, fig.cap="Forest plot for NNT (benefit = NNTB, harm = NNTH) in a meta-analysis. Figure reproduced from Figure 3 in @altman1998.", fig.align="center", fig.width = 9.5, echo = FALSE}

## Reproducing figure from altman 1998


## NNT

CABRI <- 1/c(11.2, 21.5, 260); ss_C <- 513 + 541
RITA <- 1/c(6.9, 10, 18.3); ss_R <- 501 + 510
EAST <- 1/c(6.1, 10.6, 40.2); ss_E <- 194 + 198
GABI <- 1/c(7.5, 31.2, -14.5); ss_G <- 177 + 182
OTHER <- 1/c(13, 29.3, -119); ss_O <- 76 + 76 + 70 + 72 + 66 + 68 + 63 + 64

OVERALL <- 1/c(11.2, 15.2, 24.2)


mat_stud <- matrix(c(CABRI, RITA, EAST, GABI, OTHER, OVERALL), nrow = 6, byrow = T)
mat_ss <- c(ss_C, ss_R, ss_E, ss_G, ss_O)
stud_names <- c("CABRI", "RITA", "EAST", "GABI", "Other", "Overall")




plot(NA,
     xlim = c(0.17, -0.2),
     ylim = c(1, 7.5),
     xaxt = "n",
     yaxt = "n",
     xlab = "",
     ylab = "Study")

for (i in 1:nrow(mat_stud)){
  start <-7
segments(y0 = start - i , y1 = start - i , x0 = mat_stud[i, 3], x1 = mat_stud[i, 1])
points(x = mat_stud[i, 2], y = start - i,
       cex = mat_ss[i]/200,
       pch = 15)

if (i %in% c(1, 2, 3, 6)) {
text(x = - 0.15, y = start - i,
     labels = paste0(round(1/mat_stud[i, 2], 1),
                     " (", round(1/mat_stud[i, 1], 1), " to ",
                     round(1/mat_stud[i, 3], 1), ")"))
} else {
  text(x = -0.15, y = start - i,
      labels = bquote(.(round(1/mat_stud[i, 2], 1)) ~ "(NNTB" ~
                        .(round(1/mat_stud[i, 1], 1)) ~ "to" ~ infinity ~
                        "to NNTH" ~ .(abs(round(1/mat_stud[i, 3], 1))) * ")"))

}

text(x = -0.15, 7, expression(bold("NNTB (95% CI)")))
}

axis(1, at = 1/c(6, 10, 20, 50, 100000000, -50, -20, -10),
     labels = c(6, 10, 20, 50, expression(infinity), 50, 20, 10))
axis(2, at = 1:6, labels = rev(stud_names), las = 1, cex.axis = 0.8)

abline(v = 0)

x1 <- 1/c(11.2,15.5,24.2, 15.2, 11.2)
y1 <- c(1,1.2,1,0.8,1)

polygon(x1,y1,col=2,border=2)


mtext("NNT (Benefit)", side = 1, line = 3, cex = 1.2, adj = 0)  # Bottom
mtext("NNT (Harm)", side = 1, line = 3, cex = 1.2, adj = 1)

```


#### Relative Risk {-}

The relative risk (RR) is also called *risk ratio*. The estimated death risks in both treatment groups from Example \@ref(exm:apsac) are

-  $x_1/n_1=9/162=5.6\%$ for APSAC and 
-  $x_0/n_0=19/151=12.6\%$ for Heparin.

The estimated RR is therefore

$$\widehat{\RR} = \frac{5.6\%}{12.6\%} = 0.44.$$

The calculation of a CI for the RR is based on the logRR as explained in Table \@ref(tab:CIRR). With the standard error of the log RR

\[
\SE(\color{red}{\log}(\widehat{\RR})) = 
\sqrt{\frac{1}{x_1}-\frac{1}{n_1}+\frac{1}{x_0}-\frac{1}{n_0}}
\]

and the corresponding \emph{95\% error factor} 
\[
  \EF_{.95} = \exp\left\{1.96 \cdot \SE(\color{red}{\log}(\widehat{\RR}))\right\},
\]
we can directly calculate the limits of the CI for the RR as

\begin{equation}
(\#eq:rrci)
\widehat{\RR}/\EF_{.95} \text{ and } \widehat{\RR} \cdot \EF_{.95}.
\end{equation}

This calculation is implemented in the `R` function
`biostatUZH::confIntRiskRatio()`. 



```{r echo=TRUE}
x <- rev(x)
n <- rev(n)
(ci.rr <- confIntRiskRatio(x, n))
``` 



```{r CIRR, echo = FALSE}

# Define the data frame
data <- data.frame(
  Quantity = c("RR", "", "log RR"),
  Estimate = c("0.44", "<span style='color:red;'>&darr; log &darr;</span>", "-0.82"),
  Standard_Error = c("-", "", "0.39"),
  CI = c("0.21 to 0.95", "<span style='color:red;'>&uarr; exp &uarr;</span>", "-1.58 to -0.06")
)

# Create the table using knitr::kable
kable(data, escape = FALSE, format = "html", table.attr = "class='table table-striped table-hover'", 
      col.names = c("Quantity", "Estimate", "Standard Error", "95%-confidence interval"), 
      caption = "Calculation of a CI for the RR based on the log RR.")


# data <- data.frame(
#   Quantity = c("RR", "", "\\log RR"),
#   Estimate = c("0.44", "\\color{red}{\\downarrow} \\color{red}{\\log} \\color{red}{\\downarrow}", "-0.82"),
#   Standard_Error = c("-", "", "0.39"),
#   CI = c("0.21 to 0.95", "\\color{red}{\\uparrow} \\color{red}{\\exp} \\color{red}{\\uparrow}", "-1.58 to -0.06")
# )
# 
# # Create the table
# kable(data, escape = FALSE, booktabs = TRUE, col.names = c("Quantity", "Estimate", "Standard Error", "95%-confidence interval"), caption = "Calculation of a CI for the RR based on the log RR.") %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, position = "center")
```


The square-and-add method can also be applied to ratio measures such as the risk ratio [@Newcombe, Section 7.3.4], but this is rarely used in practice. One reason might be that the simple approach \@ref(eq:rrci) based on error factors is -- by construction -- not prone to overshoot below zero. 


#### Relative Risk Reduction {-}

Either $\ARR$ or $\RR$ can be used to estimate $\RRR$: 
\begin{eqnarray*}
\widehat{\RRR} & = & \frac{\widehat{\ARR}}{\widehat{\pi}_0} \ = \ \frac{`r round(ci.rd$rd, 2)`}{`r round(p2, 3)`} \ = \ `r round(rrr*100, 0)`\% \mbox{ or} \\
\widehat{\RRR} & = & 1-\widehat{\RR} \ = \ 1 - `r round(rr, 2)` \ = \ `r round(rrr*100, 0)`\%. 
\end{eqnarray*}
A CI for $\RRR$ can be obtained based on the limits
$\mbox{L}_{\mbox{RR}}$ and $\mbox{U}_{\mbox{RR}}$ of the CI for $\RR$: 

\begin{eqnarray*}
    (1 - \mbox{U}_{\mbox{RR}}) \mbox{ to } (1 - \mbox{L}_{\mbox{RR}}) & = & 
    (1 - 0.95) \mbox{ to } (1 - 0.21) \\ & = & 0.05 \mbox{ to } 0.79 
\end{eqnarray*}

So, the risk of death with APSAC has been reduced by
`r round(rrr*100, 0)`\% (95\% CI: 5\% to 79\%) compared to Heparin. 


#### Odds Ratio {-}

```{r 2x2apsac, results='asis'}
# Load necessary libraries
library(knitr)
library(kableExtra)

# Create the data frame
data <- data.frame(
  Therapy = c("APSAC", "Heparin", ""),
  Yes = c("$a=9$", "$c=19$", ""),
  No = c("$b=153$", "$d=132$", ""),
  Total = c("$162$", "$151$", "$n = 313$")
)

# Create the table
kable(data, escape = FALSE, booktabs = TRUE, col.names = c("", "Yes", "No", "Total"), caption = "$2\\times 2$ table for the APSAC study.", 
      label = NA) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, position = "center") %>%
  add_header_above(c("", "Dead" = 2, ""))
```

From Table \@ref(tab:2x2apsac), we can read that the estimated odds of death for 
APSAC are $a/b = 9/153$ ($c/d=19/132$ for Heparin). The estimated OR is therefore
\[
\widehat{\OR} = \frac{a / b}{c / d} = \frac{9 / 153}{19 / 132} = \frac{9 \cdot
  132}{153 \cdot 19} \ = `r round(9*132/(153*19),2)`.
\]
This means that the odds of death are 59\% lower under APSAC than under
Heparin treatment. The rearrangement
\begin{equation}
(\#eq:or)
\widehat{\OR}=(a\cdot d) / (b \cdot c)
\end{equation}
motivates the alternative name *cross-product ratio*.

```{r apsacSurvival, results='asis'}
# Load necessary libraries
library(knitr)
library(kableExtra)

# Create the data frame
data <- data.frame(
  Therapy = c("APSAC", "Heparin"),
  dead = c(9, 19),
  alive = c(153, 132),
  total = c(162, 151),
  Percent_alive = c("94.4\\%", "87.4\\%"),
  Standard_error = c("1.8\\%", "2.7\\%"),
  CI = c("98.0 to 90.9\\%", "92.7 to 82.1\\%")
)

# Create the table
kable(data, escape = FALSE, booktabs = TRUE, col.names = c("", "Dead", "Alive", "Total", "Percent Alive", "Standard Error", "95% CI"), caption = "Survival probability in the APSAC study.", 
      label = NA) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, position = "center")
```


```{r echo=F}
my.OR <- 9*132/(153*19)
``` 

An advantage of the ORs is that they can be inverted for complementary events. If we consider the *survival probability* rather than the *death risk* as in Table \@ref(tab:apsacSurvival), we can see that:

-  The odds ratio for *death risk* is $\OR=`r round(my.OR,2)`$.
-  The odds ratio for *survival* then is

  \[
  \frac{(1-\pi_1)/\pi_1}{(1-\pi_0)/\pi_0} = \frac{\pi_0/(1-\pi_0)}{\pi_1/(1-\pi_1)} = 1/\OR = 1/`r round(my.OR,2)` = `r round(1/my.OR,2)`.
  \]

Such a relationship does not hold for relative risks:
 \[
 1/\RR = 1/0.44 = 2.25,  \mbox{ but } 94.4\%/87.4\% = 1.08.
 \]
 
A disadvantage of the ORs is their noncollapsibility [@Senn2]. 
Consider a hypothetical example with two therapies 
and two strata. Table \@ref(tab:strat) presents a contingency table 
stratified by strata, while Table \@ref(tab:collapsed) present the collapsed 
contingency table. 
```{r }
a1 <- 80
b1 <- 20
c1 <- 60
d1 <- 40

or1 <- a1*d1/(b1*c1)

a2 <- 60
b2 <- 40
c2 <- 36
d2 <- 64
or2 <- a2*d2/(b2*c2)

a <- a1+a2
b <- b1+b2
c <- c1+c2
d <- d1+d2
or <- a*d/(b*c)


``` 

```{r strat, echo = FALSE}

# Create the data frame
data <- data.frame(
  Therapy = c("Therapy A", "Therapy B"),
  Success_1_yes = c(a1, c1),
  Success_1_no = c(b1, d1),
  Success_1_total = c(a1 + b1, c1 + d1),
  Success_2_yes = c(a2, c2),
  Success_2_no = c(b2, d2),
  Success_2_total = c(a2 + b2, c2 + d2)
)

# Create the table
kable(data, escape = FALSE, booktabs = TRUE, col.names = c("", "Yes", "No", "Total", "Yes", "No", "Total"), caption = "Stratified contingency table", label = NA) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, position = "center") %>%
  add_header_above(c("", "Stratum 1" = 3, "Stratum 2" = 3)) %>%
  column_spec(2:7, border_left = TRUE)
```



```{r collapsed, echo = FALSE}
# Define your data

# Create the data frame
data <- data.frame(
  Therapy = c("Therapy A", "Therapy B"),
  Yes = c(a, c),
  No = c(b, d),
  Total = c(a + b, c + d)
)

# Create the table
kable(data, escape = FALSE, booktabs = TRUE, col.names = c("", "Yes", "No", "Total"), caption = "Collapsed contingency table", 
      label = NA) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, position = "center")
```





-  The OR for Stratum 1 is $\mbox{OR} = \frac{`r a1` \cdot 
`r d1`}{`r b1` \cdot `r c1`} = 
`r format(or1, digits=2, nsmall=2)`$

-  The OR for Stratum 2 is $\mbox{OR} = \frac{`r a2` \cdot 
`r d2`}{`r b2` \cdot `r c2`} = 
`r format(or2, digits=2, nsmall=2)`$
-  The OR from the collapsed analysis is 
$\mbox{OR} = \frac{`r a` \cdot `r d`}{`r b` \cdot `r c`} 
= `r format(or, digits=2, nsmall=2)`$

$\rightarrow$ The ORs are the same in both strata, but the OR collapsed 
over strata is different.



As for $\RR$ (see Table \@ref(tab:CIRR)), we calculate the standard error of the OR on the log scale:
\begin{equation}
(\#eq:orse)
  \SE(\color{red}{\log}(\widehat{\OR})) = \sqrt{\frac{1}{a}+\frac{1}{b}+\frac{1}{c}+\frac{1}{d}}.
\end{equation}

A multiplicative Wald CI can be directly calculated using the 95\% error factor 

\[
  \EF_{.95} = \exp\left\{1.96 \cdot \SE(\color{red}{\log}(\widehat{\OR}))\right\}.
\]
Note that CIs for odds ratios may differ even if group sample sizes remain the same:

```{r echo=TRUE}
x <- c(25, 25)
n <- c(50, 50)
(ci.or1 <- confIntOddsRatio(x, n))

x <- c(1, 1)
n <- c(50, 50)
(ci.or2 <- confIntOddsRatio(x, n))
``` 
What matters is the number of events.
  
  
A problem of the estimate \@ref(eq:or) is that it can become infinite
if either $b=0$ or $c=0$. Likewise, the standard error \@ref(eq:orse)
of the log odds ratio will be infinte if at least one of the entries
$a$, $b$, $c$ or $d$ is zero. A modification suggested in the
literature is to add $1/2$ to all entries $a$, $b$, $c$ and $d$. This
prevents problems with small number of events and also reduces the
potential bias of the original estimate, see for example
@spiegelhalter2004, Section 2.4.1. Another estimate of the odds ratio
is the conditional maximum likelihood estimate. This is related to
Fisher's exact test as it is based on numerically maximizing the
hypergeometric likelihood, which depends only on the odds ratio and is
obtained by conditioning on the margins sums. The conditional MLE
estimate is often reported together with the $P$-value from Fisher's
exact test, as in the `R` function `fisher.test()`. However, it has the
same problem as the standard (unconditional) MLE \@ref(eq:or) that it
becomes infinite if either $b$ or $c$ is zero.
  
  
#### Odds Ratios and Relative Risks {-}


There are the following relations between the OR and the RR:

-  If $\pi_0=\pi_1$ then $\OR = \RR = 1$.
-  OR and RR always go in the same direction ($<1$ or $>1$).
-  If $<1$, then $\OR < \RR$.
-  If $>1$, then $\OR > \RR$.
-  Rare disease assumption: 
If disease risks $\pi_0$ and $\pi_1$ are small, then
  $\OR \approx \RR$.    

The function `Epi::twoby2()` computes the RR, OR (in two versions) 
and ARR (probability difference).
The second version of the odds ratio is the conditional Maximum Likelihood 
estimate under a hypergeometric likelihood function.
There is no closed-form expression for this estimate, which
may explain why it is rarely used, but it is compatible to the 
$P$-value from Fisher's exact test (denoted here as `Exact P-value`). 


  
```{r echo=T, warning=FALSE}
library(Epi)
twoby2(APSAC.table)
```

Compatible $P$-values can be obtained for each of these effect estimates and the corresponding standard error. They will be similar, but not identical:

```{r echo=TRUE}

z <- c(arr/se.arr, log(rr)/se.log.rr, log(or)/se.log.or)
names(z) <- c("risk difference", "log relative risk", "log odds ratio")
## transform normal test statistics z to two-sided p-values
pvalues <- biostatUZH::z2p(z)
biostatUZH::formatPval(pvalues)
```

<!-- The one for OR is called `Asymptotic P-value` in `twoby2()`. -->
<!-- The one for ARR is based on the standard error \@ref(eq:arr.se). The alternative standard error -->
<!-- \begin{equation} -->
<!-- (\#eq:arr.se2) -->
<!-- \SE(\widehat{\ARR}) = \sqrt{p (1-p) \left(\frac{1}{n_0}+\frac{1}{n_1}\right)} -->
<!-- \end{equation} -->
<!-- where $p = (x_0 + x_1)/(n_0 + n_1)$ is an estimate of the common risk, assuming the null hypothesis of no difference between the two groups is true, can also be used for testing. The squared test statistic $\widehat{\ARR}^2/\SE(\widehat{\ARR})^2$ with standard error \@ref(eq:arr.se2} turns out to be identical to the test statistic from the $\chi^2$-test (without continuity correction), so the (two-sided) $P$-values will be identical.  -->



#### Absolute and relative effect measures {-}

Let us consider an example of an RCT with 
\begin{eqnarray*}  
    \mbox{death risk} &= & \left\{ \begin{array}{rl} 0.3\% & \mbox{in 
  the placebo group} \\ 
    0.1\% & \mbox{in the treatment group} 
    \end{array} \right. 
\end{eqnarray*}
Then we have $\ARR=0.2\%= 0.002$ and $\NNT=500$, so there is a *very small absolute effect* of treatment. However, we have $\RR=1/3$ and $\RRR = 2/3 = 67\%$, so there is a *large relative effect* of treatment. 
We cannot transform absolute to relative effect measures (and vice versa) without knowledge of the underlying risks.


## Adjusting for baseline observations

For binary outcomes, adjusting for baseline variables is usually done using *logistic regression* and will produce *adjusted odds ratios*. Alternatively, the *Mantel-Haenszel method* (MH) can be used, which
gives a *weighted average* of strata-specific odds ratios. The MH method can also be applied to strata-specific risk ratios. However, adjustment for continuous variables using MH is only possible after suitable categorization. 


### Logistic regression

```{r echo=F}
puva <- read.table("data/puva.txt", header=TRUE)
puva$treatment <- factor(puva$treatment, 
                         levels=c("PUVA","TL-01"))
puva$plaqueSize <- factor(puva$plaqueSize, 
                       levels=c("Small","Large"))
puva <- puva[c(1,3,2,4),]
puva <- puva[,c(2,1,3,4)]
t <- puva$total
``` 

:::{.example #puva}
The PUVA trial [@Gordon1999] compares PUVA 
(oral methoxsalen followed by UVA exposure) versus TL-01 lamp therapy for treatment of
psoriasis. The primary outcome is clearance of psoriasis (yes/no)
at or before the end of the treatment.  
The treatment allocation used RPBs stratified according to whether predominant 
plaque size was large or small. This ensures a balanced distribution 
in treatment arms (`r t[1]`:`r t[3]` vs. `r t[2]`:`r t[4]`).
:::


```{r echo=T}
print(puva)
``` 

The unadjusted analyis can be performed as follows: 
```{r echo=T, results="asis"}
m1 <- glm(cbind(cleared, total-cleared) ~ treatment, 
          data=puva, family=binomial)
## tableRegression gives profile confidence intervals
knitr::kable(tableRegression(m1, latex = FALSE, xtable = FALSE))
``` 


The strata-specific estimates are obtained using:
```{r echo=T, results="asis"}
m2Small <- glm(cbind(cleared, total-cleared) ~ treatment, 
          subset=(plaqueSize=="Small"), data=puva, family=binomial)
knitr::kable(tableRegression(m2Small, latex = FALSE, xtable = FALSE))
m2Large <- glm(cbind(cleared, total-cleared) ~ treatment, 
          subset=(plaqueSize=="Large"), data=puva, family=binomial)
knitr::kable(tableRegression(m2Large, latex = FALSE, xtable = FALSE))
``` 

Finally,  the adjusted analysis with logistic regression is:
```{r echo=T, results="asis"}
m3 <- glm(cbind(cleared, total-cleared) ~ treatment + plaqueSize, 
          data=puva, family=binomial)
knitr::kable(tableRegression(m3, latex = FALSE, xtable = FALSE))
```


The adjusted treatment effect is
$\widehat{\OR} = `r format(exp(coef(m3)[2]),nsmall=2, digits=2)`$
with 95\% CI from 
$`r format(exp(confint(m3)[2,1]),nsmall=2, digits=2)`$ to 
$`r round(exp(confint(m3)[2,2]),2)`$.
Logistic regression also quantifies the effect of the variable used for 
adjustment, here plaque size, and gives a better model fit: 

```{r, echo = TRUE}
anova(m1, m3)
```



## Ordinal outcomes

Many clinical trials yield outcomes on an ordered categorical scale
such as "very good", "good", "moderate", "poor". Such data can be analysed 
using proportional odds regression techniques. 

Suppose that we have $k = 1, \ldots K$ categories and define the odds ratio 
OR$_k$ at each cut-off point $k = 1, \ldots K - 1$ via 
$$
\text{OR}_k = \frac{\P(Y_\text{A} \le k)/\P(Y_\text{A} > k)}
{\P(Y_\text{B} \le k)/\P(Y_\text{B} > k)},
$$
where $Y_\text{A}$ and $Y_\text{B}$ denote the outcomes from treatment group A and B, respectively.
The *proportional odds logistic regression model* assumes 
$\text{OR}_k = \text{OR}$ for all $k = 1,\dots, K-1$.
Sample size methods are available in the `R` function 
`Hmisc::posamsize()`.

:::{.example #arthritis}
A clinical trial has been conducted to compare the drug auranofin with 
placebo for the treatment of rheumatoid arthritis [@Bombardier1986; @Lipsitz1994].
Patients were 
randomized to one of the two treatments for the entire study. 
The ordered response is the self-assessment of arthritis classified as 
(1) poor, (2) fair, or (3) good. Of the 303 randomized patients, 
299 were observed at both baseline and follow-up. 
:::

Here is what the data at baseline and at follow-up looks like: 

```{r, echo = FALSE}

arthritis <- read.table("data/arthritis.txt", header=TRUE)
sel <- which(arthritis$age > 100)
arthritis <- arthritis[-sel,]
sel <- which(is.na(arthritis$y1))
arthritis <- arthritis[-sel,]


arthritis$treatment <- ifelse(arthritis$trt == 1, "Placebo", "Auranofin")
arthritis$treatment <- factor(arthritis$treatment, levels=rev(c("Auranofin", "Placebo")))

arthritis$baseline5 <- as.factor(arthritis$baseline)
arthritis$followup5 <- factor(arthritis$y1)

arthritis$baseline <- ifelse(arthritis$baseline <= 2, "Poor", ifelse(arthritis$baseline == 3, "Fair", "Good"))
arthritis$followup <- ifelse(arthritis$y1 <= 2, "Poor", ifelse(arthritis$y1 == 3, "Fair", "Good"))
arthritis$y2 <- ifelse(arthritis$y2 <= 2, "Poor", ifelse(arthritis$y2 == 3, "Fair", "Good"))
arthritis$y3 <- ifelse(arthritis$y3 <= 2, "Poor", ifelse(arthritis$y3 == 3, "Fair", "Good"))

arthritis$baseline <- factor(arthritis$baseline, levels=c("Poor", "Fair", "Good"))
arthritis$followup <- factor(arthritis$followup, levels=c("Poor", "Fair", "Good"))

arthritis$y2 <- factor(arthritis$y2, levels=c("Poor", "Fair", "Good"))
arthritis$y3 <- factor(arthritis$y3, levels=c("Poor", "Fair", "Good"))


library(MASS)
polr1 <- polr(followup ~ treatment, data=arthritis)
polr2 <- polr(followup ~ treatment + baseline, data=arthritis)
polr3 <- polr(followup ~ treatment + baseline + age, data=arthritis)
```

```{r, echo = TRUE}
addmargins(table(arthritis$baseline, arthritis$treatment))
addmargins(table(arthritis$followup, by=arthritis$treatment))
```


The cumulative odds ratios are 
```{r, echo = TRUE}
t <- table(arthritis$followup, by=arthritis$treatment)
x1 <- t[1,]
n <- apply(t, 2, sum)
confIntOddsRatio(x=x1, n=n)

x2 <- t[1,] + t[2,]
n <- apply(t, 2, sum)
confIntOddsRatio(x=x2, n=n)
```
and so, the proportional odds assumption is questionable. 

A proportional odds logistic regression yields: 

```{r, echo = TRUE}
library(MASS)
## polr: proportional odds logistic regression
polr1 <- polr(followup ~ treatment, data=arthritis)

print(s1 <- summary(polr1))
## odds ratio is exp of coefficient
CoefTable <-  s1$coefficients
printWaldCI(theta=CoefTable[1,"Value"], se=CoefTable[1,"Std. Error"], FUN=exp)
```

Adjusting for baseline gives:

```{r, echo = TRUE}
library(MASS)
## polr: proportional odds logistic regression
polr2 <- polr(followup ~ treatment + baseline, data=arthritis)

print(s2 <- summary(polr2))
## odds ratio is exp of coefficient
CoefTable <-  s2$coefficients
printWaldCI(theta=CoefTable[1,"Value"], 
            se=CoefTable[1,"Std. Error"], FUN=exp)
```

The second model (`polr2`) has a better model fit than the first (`polr1`): 
```{r, echo = TRUE}
anova(polr1, polr2)
```


We can now compare observed and fitted counts for each covariate 
combination and use a $\chi^2$-goodness-of-fit tests: 

```{r, echo = FALSE}
library(kableExtra)

t <- table(arthritis$followup, arthritis$treatment, arthritis$baseline)
## print(t)

names <- matrix(NA, nrow=6, ncol=1)
expected1 <- expected <- observed <- matrix(NA, nrow=6, ncol=3)
myfitted1 <- fitted(polr1)
myfitted2 <- fitted(polr2)
ii <- 1
for(treatment in c("Auranofin", "Placebo")){
    for(baseline in c("Poor", "Fair", "Good")){
        sel <- ((arthritis$treatment==treatment) & (arthritis$baseline==baseline))
        names[ii,] <- paste0(treatment, ", ", baseline, " baseline")
        observed[ii,] <- table(arthritis[sel, "followup"])
        expected1[ii,] <- apply(myfitted1[sel,], 2, sum)
        expected[ii,] <- apply(myfitted2[sel,], 2, sum)
        ii <- ii + 1
    }
}

output <- cbind(observed, expected)
output <- matrix(apply(cbind((observed-expected)^2/(expected)), 1, sum), ncol=1)/2
output <- cbind((observed-expected)^2/(expected))


rownames(output)  <- names
rownames(observed)  <- rownames(expected) <- names
colnames(observed) <- c("Obs Poor", "Obs Fair", "Obs Good") 
colnames(expected) <- c("Exp Poor", "Exp Fair", "Exp Good") 
colnames(observed) <- c("Observed", "Observed", "Observed") 
colnames(expected) <- c("Fitted", "Fitted", "Fitted") 


D2 <- sum(2*observed*(log(observed/expected)))
Chi2 <- sum((observed-expected)^2/expected)
D1 <- sum(2*observed*(log(observed/expected1)))
Chi1 <- sum((observed-expected1)^2/expected1)

output <- cbind(observed, round(expected, 1))[,c(1,4,2,5,3,6)]

# Generate the table with specified rounding and alignment
kable(output, digits = c(0, 1, 0, 1, 0, 1), align = "r", booktabs = TRUE) %>%
  add_header_above(c(" " = 1, "Poor followup" = 2, "Fair followup" = 2, "Good followup" = 2))

Observed <- observed
Fitted <- expected
```
```{r, echo = TRUE}
Chi2 <- sum((Observed-Fitted)^2/Fitted)
print(p <- pchisq(Chi2, df=12, lower.tail=FALSE))
```


There is some evidence for poor model fit ($p=`r biostatUZH::formatPval(p)`$).




## Additional references

Relevant references for this chapter are in particular Chapters 13 
"The Analysis of Cross-Tabulations" and 15.10 "Logistic Regression"
in @bland as well as Chapter 7.1--7.4 "Further Analysis: Binary Data" in @matthews.
The use of odds ratios is discussed in @altmansackett1996 and
@altmandeeks1998. Studies where the methods from this chapter are used in
practice are for example @heal, @fagerstroem and @vadillo.

